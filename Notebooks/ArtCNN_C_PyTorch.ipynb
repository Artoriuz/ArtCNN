{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56VtMIL-GVvi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class PSNRMetric(nn.Module):\n",
        "    def forward(self, y_true, y_pred):\n",
        "        y_pred = torch.clamp(y_pred, 0, 1)\n",
        "        mse = torch.mean((y_true - y_pred) ** 2)\n",
        "        psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
        "        return psnr.item()\n",
        "\n",
        "class SSIMMetric(nn.Module):\n",
        "    def forward(self, y_true, y_pred):\n",
        "        y_pred = torch.clamp(y_pred, 0, 1)\n",
        "        ssim = TF.ssim(y_true, y_pred, data_range=1.0)\n",
        "        return torch.mean(ssim).item()\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, filters=64, upscale_factor=2):\n",
        "        super(Model, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv_skip1 = nn.Conv2d(1, filters, kernel_size=3, padding='same')\n",
        "        self.conv_inner = nn.ModuleList([nn.Conv2d(filters, filters, kernel_size=3, padding='same') for _ in range(16)])\n",
        "        self.conv_skip2 = nn.Conv2d(filters, filters, kernel_size=3, padding='same')\n",
        "        self.conv_out = nn.Conv2d(filters, 4, kernel_size=3, padding='same')\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv_skip1(input)\n",
        "        x0 = x\n",
        "        for conv_layer in self.conv_inner:\n",
        "            x = self.relu(conv_layer(x))\n",
        "        x1 = self.conv_skip2(x)\n",
        "        x2 = self.conv_out(x1 + x0)\n",
        "        output = self.pixel_shuffle(x2)\n",
        "        return output\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        init.xavier_uniform_(tensor=self.conv_skip1.weight)\n",
        "        for conv_layer in self.conv_inner:\n",
        "            init.kaiming_uniform_(tensor=conv_layer.weight, nonlinearity='relu')\n",
        "        init.xavier_uniform_(tensor=self.conv_skip2.weight)\n",
        "        init.xavier_uniform_(tensor=self.conv_out.weight)\n",
        "\n",
        "model = Model()\n",
        "model.load_state_dict(torch.load(\"/content/model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtI6a-2lImmV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Datasets/DIV2K_Train_LR.zip /content/LR.zip\n",
        "!cp /content/drive/MyDrive/Datasets/DIV2K_Train_HR.zip /content/HR.zip\n",
        "\n",
        "!unzip /content/LR.zip\n",
        "!unzip /content/HR.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8V58APqJw71"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/HR\n",
        "!rm -rf /content/LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dXVkWHw6tix"
      },
      "outputs": [],
      "source": [
        "# Load data into memory\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "filelist1 = sorted(glob.glob('/content/LR/*'))\n",
        "train_in = []\n",
        "for myFile in filelist1:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    train_in.append(image)\n",
        "train_in = np.array(train_in).astype(np.float32) / 255.0\n",
        "train_in = np.expand_dims(train_in, axis = 1)\n",
        "\n",
        "filelist2 = sorted(glob.glob('/content/HR/*'))\n",
        "train_ref = []\n",
        "for myFile in filelist2:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    train_ref.append(image)\n",
        "train_ref = np.array(train_ref).astype(np.float32) / 255.0\n",
        "train_ref = np.expand_dims(train_ref, axis = 1)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "train_in_tensor = torch.tensor(train_in)\n",
        "train_ref_tensor = torch.tensor(train_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_Y7_EIsQwEV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataset = TensorDataset(train_in_tensor, train_ref_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Move model to device if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to train mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Print epoch statistics\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.8f}')\n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(model.state_dict(), \"/content/model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TJBCRVEUBQZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image = cv2.imread('/content/downscaled.png', cv2.IMREAD_GRAYSCALE)\n",
        "image = np.array(image).astype(np.float32) / 255.0\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = torch.tensor(image)\n",
        "\n",
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "image = image.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "\n",
        "output = output.cpu().numpy()\n",
        "output = np.squeeze(output)\n",
        "output = np.clip(output, 0.0, 1.0)\n",
        "output = np.around(output * 255.0)\n",
        "output = output.astype(np.uint8)\n",
        "\n",
        "cv2.imwrite('/content/prediction.png', output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfINCDNYZrCZ"
      },
      "outputs": [],
      "source": [
        "!pip install onnx\n",
        "import onnx\n",
        "\n",
        "x = torch.ones((1, 1, 1920, 1080))  # N x C x W x H\n",
        "x = x.to(device)\n",
        "torch.onnx.export(\n",
        "    model, x, '/content/c16f64.onnx',\n",
        "    input_names = ['input'],\n",
        "    output_names = ['output'],\n",
        "    dynamic_axes={\n",
        "        'input' : {0 : 'batch', 2: 'width', 3: 'height'},\n",
        "        'output' : {0 : 'batch', 2: 'width', 3: 'height'},\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
