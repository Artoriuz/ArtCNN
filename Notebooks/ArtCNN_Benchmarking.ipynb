{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5pa960pwesE"
      },
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "def psnr_metric(y_true, y_pred):\n",
        "    psnr = tf.image.psnr(y_true, y_pred, max_val=1)\n",
        "    return tf.reduce_mean(psnr)\n",
        "\n",
        "def ssim_metric(y_true, y_pred):\n",
        "    ssim = tf.image.ssim(y_true, y_pred, max_val=1)\n",
        "    return tf.reduce_mean(ssim)\n",
        "\n",
        "def msssim_metric(y_true, y_pred):\n",
        "    msssim = tf.image.ssim_multiscale(y_true, y_pred, max_val=1)\n",
        "    return tf.reduce_mean(msssim)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings\n",
        "filters = 96\n",
        "blocks = 16\n",
        "act = \"relu\"\n",
        "kernel_size = 3\n",
        "\n",
        "class DepthToSpace(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = tf.nn.depth_to_space(x, 2)\n",
        "        x = keras.ops.clip(x, 0.0, 1.0)\n",
        "        return x\n",
        "\n",
        "def res_block(input, filters=filters, kernel_size=kernel_size):\n",
        "    x = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same', activation=act)(input)\n",
        "    x = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same', activation=act)(x)\n",
        "    x = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
        "    x = keras.layers.Add()([x, input])\n",
        "    return x\n",
        "\n",
        "# Build the model:\n",
        "inputs = keras.layers.Input(shape=(None,None,1))\n",
        "conv0 = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same')(inputs)\n",
        "\n",
        "x = res_block(conv0)\n",
        "for _ in range(blocks - 1):\n",
        "    x = res_block(x)\n",
        "\n",
        "# Feature Fusion\n",
        "conv1 = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
        "mix = keras.layers.Add()([conv1, conv0])\n",
        "\n",
        "# Upsampler\n",
        "features = keras.layers.Conv2D(filters=4, kernel_size=kernel_size, padding='same')(mix)\n",
        "outputs = DepthToSpace()(features)\n",
        "\n",
        "# Defining the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "# Compile the model.\n",
        "model.compile(optimizer='Adam', loss='mae', metrics=[psnr_metric, ssim_metric, msssim_metric])"
      ],
      "metadata": {
        "id": "v53IXzsePZa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r8WU2Ftzhja"
      },
      "source": [
        "# Download data from gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/tmp/r16f96.keras /content/r16f96.keras\n",
        "\n",
        "!cp /content/drive/MyDrive/Datasets/FHD_Anime.zip /content/FHD_Anime.zip\n",
        "!unzip /content/FHD_Anime.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/r16f96.keras\", skip_mismatch=True)"
      ],
      "metadata": {
        "id": "EazHYf0Spzfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FHD Anime\n",
        "number_files = len(os.listdir('/content/FHD_Anime/'))\n",
        "metrics_array = np.empty([number_files, 4])\n",
        "idx = 0\n",
        "\n",
        "filelist = sorted(glob.glob('/content/FHD_Anime/*.png'))\n",
        "\n",
        "for myFile in filelist:\n",
        "    test_ref = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    test_ref = cv2.cvtColor(test_ref, cv2.COLOR_BGR2GRAY, 0)\n",
        "    test_in = cv2.resize(test_ref, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT)\n",
        "\n",
        "    test_ref = np.array(test_ref).astype(np.float32) / 255.0\n",
        "    test_ref = np.clip(test_ref, 0.0, 1.0)\n",
        "    test_ref = np.expand_dims(test_ref, axis=-1)\n",
        "    test_ref = np.expand_dims(test_ref, axis=0)\n",
        "\n",
        "    test_in = np.array(test_in).astype(np.float32) / 255.0\n",
        "    test_in = np.clip(test_in, 0.0, 1.0)\n",
        "    test_in = np.expand_dims(test_in, axis=-1)\n",
        "    test_in = np.expand_dims(test_in, axis=0)\n",
        "\n",
        "    metrics_array[idx, :] = np.array(model.evaluate(test_in, test_ref, verbose=1))\n",
        "    idx = idx + 1\n",
        "\n",
        "print(filelist)\n",
        "print(metrics_array)\n",
        "np.set_printoptions(suppress=True)\n",
        "print(np.average(metrics_array, axis=0))"
      ],
      "metadata": {
        "id": "OuOWITeMT0pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filelist1 = sorted(glob.glob('/content/FHD_Anime/*.png'))\n",
        "test_in = []\n",
        "for myFile in filelist1:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT)\n",
        "    test_in.append(image)\n",
        "test_in = np.array(test_in).astype(np.float32) / 255.0\n",
        "test_in = np.clip(test_in, 0.0, 1.0)\n",
        "test_in = np.expand_dims(test_in, axis=-1)\n",
        "print(test_in.shape)\n",
        "\n",
        "filelist2 = sorted(glob.glob('/content/FHD_Anime/*.png'))\n",
        "test_ref = []\n",
        "for myFile in filelist2:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    test_ref.append(image)\n",
        "test_ref = np.array(test_ref).astype(np.float32) / 255.0\n",
        "test_ref = np.clip(test_ref, 0.0, 1.0)\n",
        "test_ref = np.expand_dims(test_ref, axis=-1)\n",
        "print(test_ref.shape)\n",
        "\n",
        "metrics_array = np.array(model.evaluate(test_in, test_ref, batch_size=1, verbose=1))\n",
        "print(metrics_array)"
      ],
      "metadata": {
        "id": "Z3HgYAmqVQEl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}