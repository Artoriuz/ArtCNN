{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10Sw8a46w0Uk",
        "outputId": "cabb0dcd-0681-4b77-b64a-25c4fe9fb993"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade keras\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "import keras\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "56VtMIL-GVvi",
        "outputId": "56754a84-4734-42ff-b6b2-abc1766343ca"
      },
      "outputs": [],
      "source": [
        "class DepthToSpace(keras.layers.Layer):\n",
        "    def __init__(self, block_size):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def call(self, input):\n",
        "        batch, height, width, depth = keras.ops.shape(input)\n",
        "        depth = depth // (self.block_size**2)\n",
        "        x = keras.ops.reshape(input, [batch, height, width, self.block_size, self.block_size, depth])\n",
        "        x = keras.ops.transpose(x, [0, 1, 3, 2, 4, 5])\n",
        "        x = keras.ops.reshape(x, [batch, height * self.block_size, width * self.block_size, depth])\n",
        "        x = keras.activations.relu(x, max_value=1.0)\n",
        "        return x\n",
        "\n",
        "# Settings\n",
        "filters = 64\n",
        "\n",
        "# Build the model:\n",
        "inputs = keras.layers.Input(shape=(None,None,1))\n",
        "conv0 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same')(inputs)\n",
        "\n",
        "# Internal convolutions\n",
        "conv1 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv0)\n",
        "conv2 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv1)\n",
        "conv3 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
        "conv4 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv3)\n",
        "\n",
        "# # Internal convolutions\n",
        "# conv1 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv4)\n",
        "# conv2 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv1)\n",
        "# conv3 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
        "# conv4 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv3)\n",
        "\n",
        "# # Internal convolutions\n",
        "# conv1 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv4)\n",
        "# conv2 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv1)\n",
        "# conv3 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
        "# conv4 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv3)\n",
        "\n",
        "# # Internal convolutions\n",
        "# conv1 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv4)\n",
        "# conv2 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv1)\n",
        "# conv3 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
        "# conv4 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv3)\n",
        "\n",
        "# Feature Fusion\n",
        "mix_global = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same')(conv4)\n",
        "add_global = keras.layers.Add()([mix_global, conv0])\n",
        "\n",
        "# Upsampler\n",
        "features = keras.layers.Conv2D(filters=4, kernel_size=3, padding='same')(add_global)\n",
        "outputs = DepthToSpace(2)(features)\n",
        "\n",
        "# Defining the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=keras.losses.MeanAbsoluteError())\n",
        "model.summary()\n",
        "#keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "# Load weights\n",
        "model.load_weights(\"/content/c4f64.keras\", skip_mismatch=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4dXVkWHw6tix"
      },
      "outputs": [],
      "source": [
        "# Download data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Datasets/Anime_Train_LR.zip /content/LR.zip\n",
        "!cp /content/drive/MyDrive/Datasets/Anime_Train_HR.zip /content/HR.zip\n",
        "\n",
        "!unzip /content/LR.zip\n",
        "!unzip /content/HR.zip\n",
        "\n",
        "# Load data\n",
        "filelist1 = sorted(glob.glob('/content/LR/*'))\n",
        "train_in = []\n",
        "for myFile in filelist1:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    train_in.append(image)\n",
        "train_in = np.array(train_in).astype(np.float32) / 255.0\n",
        "train_in = np.clip(train_in, 0.0, 1.0)\n",
        "train_in = np.expand_dims(train_in, axis=-1)\n",
        "\n",
        "filelist2 = sorted(glob.glob('/content/HR/*'))\n",
        "train_ref = []\n",
        "for myFile in filelist2:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    train_ref.append(image)\n",
        "train_ref = np.array(train_ref).astype(np.float32) / 255.0\n",
        "train_ref = np.clip(train_ref, 0.0, 1.0)\n",
        "train_ref = np.expand_dims(train_ref, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_3V-q8V6SBF",
        "outputId": "d656b0a6-950e-4bf9-a517-be353f979d34"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=keras.losses.MeanAbsoluteError())\n",
        "history = model.fit(train_in, train_ref, epochs=1000, batch_size=64, verbose=1)\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMr-4ei_yY27"
      },
      "outputs": [],
      "source": [
        "# Make a single prediction\n",
        "input = cv2.imread('/content/downscaled.png', cv2.IMREAD_COLOR)\n",
        "input = cv2.cvtColor(input, cv2.COLOR_BGR2GRAY, 0)\n",
        "input = np.array(input).astype(np.float32) / 255.0\n",
        "input = np.clip(input, 0.0, 1.0)\n",
        "input = np.expand_dims(input, axis=0)\n",
        "input = np.expand_dims(input, axis=-1)\n",
        "\n",
        "pred = model.predict(input)\n",
        "pred = np.clip(pred, 0.0, 1.0)\n",
        "pred = np.squeeze(pred)\n",
        "pred = pred * 255.0\n",
        "pred = np.squeeze((np.around(pred)).astype(np.uint8))\n",
        "\n",
        "cv2.imwrite('/content/prediction.png', pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVEES5kX7DJY",
        "outputId": "53f1813f-60fc-4347-bf8a-66fab42fcf3e"
      },
      "outputs": [],
      "source": [
        "#Generate normal shader\n",
        "import numpy as np\n",
        "\n",
        "def generate_shader_code(current_layer, previous_layer, channels_in, channels_out):\n",
        "    passes_in = int(np.ceil(channels_in / 4))\n",
        "    passes_out = int(np.ceil(channels_out / 4))\n",
        "\n",
        "    if previous_layer.name == \"input_layer\":\n",
        "        previous_layer.name = \"LUMA\"\n",
        "\n",
        "    shader_code = \"\"\n",
        "    for pass_idx in range(passes_out):\n",
        "        if any(layer_name in current_layer.name for layer_name in [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\"]):\n",
        "            shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')}-ReLU)\\n\" #-{pass_idx}\n",
        "        elif \"conv2d\" in current_layer.name:\n",
        "            shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')})\\n\"\n",
        "        else:\n",
        "            shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')})\\n\"\n",
        "\n",
        "        shader_code += f\"//!HOOK LUMA\\n\"\n",
        "\n",
        "        if previous_layer.name == \"LUMA\":\n",
        "            shader_code += f\"//!BIND {previous_layer.name}\\n\"\n",
        "        elif \"add\" in previous_layer.name:\n",
        "            for i in range(passes_in):\n",
        "                shader_code += f\"//!BIND conv2d_{i}\\n\"\n",
        "                shader_code += f\"//!BIND conv2d_5_{i}\\n\"\n",
        "        elif \"conv2d\" in current_layer.name:\n",
        "            for i in range(passes_in):\n",
        "                shader_code += f\"//!BIND {previous_layer.name}_{i}\\n\"\n",
        "        elif \"depth\" in current_layer.name:\n",
        "            shader_code += f\"//!BIND {previous_layer.name}_0\\n\"\n",
        "\n",
        "        if \"depth\" in current_layer.name:\n",
        "            shader_code += f\"//!WIDTH LUMA.w 2.0 *\\n\"\n",
        "            shader_code += f\"//!HEIGHT LUMA.h 2.0 *\\n\"\n",
        "        else:\n",
        "            shader_code += f\"//!SAVE {current_layer.name}_{pass_idx}\\n\"\n",
        "            shader_code += f\"//!WIDTH LUMA.w\\n\"\n",
        "            shader_code += f\"//!HEIGHT LUMA.h\\n\"\n",
        "\n",
        "        shader_code += f\"//!COMPONENTS 4\\n\"\n",
        "        shader_code += f\"//!WHEN OUTPUT.w LUMA.w / 1.3 > OUTPUT.h LUMA.h / 1.3 > *\\n\\n\"\n",
        "        shader_code += \"vec4 hook() {\\n\"\n",
        "\n",
        "        if \"conv2d\" in current_layer.name:\n",
        "            biases = current_layer.get_weights()[1][pass_idx*4:(pass_idx+1)*4]\n",
        "            biases_str = \", \".join(str(w) for w in biases.flatten())\n",
        "            shader_code += f\"    vec4 result = vec4({biases_str});\\n\"\n",
        "\n",
        "            for z in range(passes_in):\n",
        "                for y in range(-1, 2):\n",
        "                    for x in range(-1, 2):\n",
        "                        weights = current_layer.get_weights()[0][y+1, x+1, z*4:(z+1)*4, pass_idx*4:(pass_idx+1)*4]\n",
        "                        weights_str = \", \".join(str(w) for w in weights.flatten())\n",
        "\n",
        "                        if weights_str:\n",
        "                            if previous_layer.name == \"LUMA\":\n",
        "                                shader_code += f\"    result += vec4({weights_str}) * {previous_layer.name}_texOff(vec2({x}, {y})).x;\\n\"\n",
        "                            elif \"add\" in previous_layer.name:\n",
        "                                shader_code += f\"    result += mat4({weights_str}) * (conv2d_5_{z}_texOff(vec2({x}, {y})) + conv2d_{z}_texOff(vec2({x}, {y})));\\n\"\n",
        "                            else:\n",
        "                                shader_code += f\"    result += mat4({weights_str}) * {previous_layer.name}_{z}_texOff(vec2({x}, {y}));\\n\"\n",
        "\n",
        "            if any(layer_name in current_layer.name for layer_name in [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\"]):\n",
        "                shader_code += \"    return max(result, vec4(0.0));\\n\"\n",
        "            else:\n",
        "                shader_code += \"    return result;\\n\"\n",
        "\n",
        "        elif \"depth\" in current_layer.name:\n",
        "            shader_code += f\"    vec4 result = vec4(0.0, 0.0, 0.0, 1.0);\\n\"\n",
        "            shader_code += f\"    vec2 f0 = fract({previous_layer.name}_0_pos * {previous_layer.name}_0_size);\\n\"\n",
        "            shader_code += f\"    ivec2 i0 = ivec2(f0 * vec2(2.0));\\n\"\n",
        "            shader_code += f\"    result.x = {previous_layer.name}_0_tex((vec2(0.5) - f0) * {previous_layer.name}_0_pt + {previous_layer.name}_0_pos)[i0.y * 2 + i0.x];\\n\"\n",
        "            shader_code += f\"    return clamp(result, 0.0, 1.0);\\n\"\n",
        "\n",
        "        shader_code += \"}\\n\\n\"\n",
        "    return shader_code\n",
        "\n",
        "################################################################################\n",
        "filters = model.layers[1].filters\n",
        "shader_code = \"\"\"// MIT License\n",
        "\n",
        "// Copyright (c) 2024 Joao Chrisostomo\n",
        "\n",
        "// Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "// of this software and associated documentation files (the \"Software\"), to deal\n",
        "// in the Software without restriction, including without limitation the rights\n",
        "// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "// copies of the Software, and to permit persons to whom the Software is\n",
        "// furnished to do so, subject to the following conditions:\n",
        "\n",
        "// The above copyright notice and this permission notice shall be included in all\n",
        "// copies or substantial portions of the Software.\n",
        "\n",
        "// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "// SOFTWARE.\n",
        "\n",
        "\"\"\"\n",
        "for i in range(1, len(model.layers)):\n",
        "    if model.layers[i].name == \"conv2d\":\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], 1, filters)\n",
        "    elif \"conv2d_6\" in model.layers[i].name:\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], filters, 4)\n",
        "    elif \"conv2d\" in model.layers[i].name:\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], filters, filters)\n",
        "    elif \"depth_to_space\" in model.layers[i].name:\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], 4, 1)\n",
        "\n",
        "print(shader_code)\n",
        "with open(\"meme.glsl\", mode=\"w\") as f:\n",
        "    f.write(shader_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Generate clever compute shader\n",
        "import numpy as np\n",
        "\n",
        "def generate_shader_code(current_layer, previous_layer, channels_in, channels_out):\n",
        "    passes_in = int(np.ceil(channels_in / 4.0))\n",
        "    passes_out = int(np.ceil(channels_out / 4.0))\n",
        "\n",
        "    if previous_layer.name == \"input_layer\":\n",
        "        previous_layer.name = \"LUMA\"\n",
        "\n",
        "    shader_code = \"\"\n",
        "    if any(layer_name in current_layer.name for layer_name in [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\"]):\n",
        "        shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')}-ReLU)\\n\"\n",
        "    else:\n",
        "        shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')})\\n\"\n",
        "    shader_code += f\"//!COMPUTE 16 16 {int(16 / passes_out)} 16\\n\"\n",
        "    shader_code += f\"//!HOOK LUMA\\n\"\n",
        "\n",
        "    if previous_layer.name == \"LUMA\":\n",
        "        shader_code += f\"//!BIND {previous_layer.name}\\n\"\n",
        "    elif \"add\" in previous_layer.name:\n",
        "        shader_code += f\"//!BIND conv2d\\n\"\n",
        "        shader_code += f\"//!BIND conv2d_5\\n\"\n",
        "    elif \"conv2d\" in current_layer.name:\n",
        "        shader_code += f\"//!BIND {previous_layer.name}\\n\"\n",
        "    elif \"depth\" in current_layer.name:\n",
        "        shader_code += f\"//!BIND {previous_layer.name}\\n\"\n",
        "\n",
        "    if \"depth\" in current_layer.name:\n",
        "        shader_code += f\"//!WIDTH LUMA.w 2.0 *\\n\"\n",
        "        shader_code += f\"//!HEIGHT LUMA.h 2.0 *\\n\"\n",
        "    else:\n",
        "        shader_code += f\"//!SAVE {current_layer.name}\\n\"\n",
        "        shader_code += f\"//!WIDTH LUMA.w {float(passes_out)} *\\n\"\n",
        "        shader_code += f\"//!HEIGHT LUMA.h\\n\"\n",
        "\n",
        "    shader_code += f\"//!COMPONENTS 4\\n\"\n",
        "    shader_code += f\"//!WHEN OUTPUT.w LUMA.w / 1.3 > OUTPUT.h LUMA.h / 1.3 > *\"\n",
        "    shader_code += \"\"\"\n",
        "#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable\n",
        "#ifdef GL_EXT_shader_explicit_arithmetic_types_float16\n",
        "#\tdefine V4 f16vec4\n",
        "#\tdefine M4 f16mat4\n",
        "#\tdefine F float16_t\n",
        "#else\n",
        "#\tdefine V4 vec4\n",
        "#\tdefine M4 mat4\n",
        "#\tdefine F float\n",
        "#endif\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    if \"conv2d\" in current_layer.name:\n",
        "        storage = \"V4\"\n",
        "        weights_storage = \"M4\"\n",
        "        load_suffix = \"\"\n",
        "        if previous_layer.name == \"LUMA\":\n",
        "            storage = \"F\"\n",
        "            weights_storage = \"V4\"\n",
        "            load_suffix = \".x\"\n",
        "\n",
        "        shader_code += \"const ivec2 ksize = ivec2(3, 3);\\n\"\n",
        "        shader_code += \"const ivec2 offset = ksize / 2;\\n\"\n",
        "        shader_code += \"const ivec2 isize = ivec2(gl_WorkGroupSize) + ksize - 1;\\n\"\n",
        "        shader_code += f\"shared {storage} inp[{passes_in}][isize.y][isize.x];\\n\"\n",
        "\n",
        "        shader_code += \"void hook() {\\n\"\n",
        "        shader_code += f\"    ivec2 base = ivec2(gl_WorkGroupID) * ivec2(gl_WorkGroupSize);\\n\"\n",
        "        shader_code += f\"    for (uint y = gl_LocalInvocationID.y; y < isize.y; y += gl_WorkGroupSize.y) {{\\n\"\n",
        "        shader_code += f\"        for (uint x = gl_LocalInvocationID.x; x < isize.x; x += gl_WorkGroupSize.x) {{\\n\"\n",
        "        for z in range(passes_in):\n",
        "            if \"add\" in previous_layer.name:\n",
        "                shader_code += f\"            inp[{z}][y][x] = {storage}(conv2d_5_mul * texelFetch(conv2d_5_raw, (base + ivec2(x,y) - offset) * ivec2({passes_in}, 1) + ivec2({z}, 0), 0) + conv2d_mul * texelFetch(conv2d_raw, (base + ivec2(x,y) - offset) * ivec2({passes_in}, 1) + ivec2({z}, 0), 0){load_suffix});\\n\"\n",
        "            else:\n",
        "                shader_code += f\"            inp[{z}][y][x] = {storage}({previous_layer.name}_mul * texelFetch({previous_layer.name}_raw, (base + ivec2(x,y) - offset) * ivec2({passes_in}, 1) + ivec2({z}, 0), 0){load_suffix});\\n\"\n",
        "\n",
        "        shader_code += f\"        }}\\n\"\n",
        "        shader_code += f\"    }}\\n\"\n",
        "        shader_code += f\"\\n    barrier();\\n\"\n",
        "        for pass_idx in range(passes_out):\n",
        "            biases = current_layer.get_weights()[1][pass_idx*4:(pass_idx+1)*4]\n",
        "            biases_str = \", \".join(str(w) for w in biases.flatten())\n",
        "            shader_code += f\"    V4 result{pass_idx} = V4({biases_str});\\n\"\n",
        "\n",
        "            for z in range(passes_in):\n",
        "                for y in range(0, 3):\n",
        "                    for x in range(0, 3):\n",
        "                        weights = current_layer.get_weights()[0][y, x, z*4:(z+1)*4, pass_idx*4:(pass_idx+1)*4]\n",
        "                        weights_str = \", \".join(str(w) for w in weights.flatten())\n",
        "\n",
        "                        if weights_str:\n",
        "                            shader_code += f\"    result{pass_idx} += {weights_storage}({weights_str}) * inp[{z}][gl_LocalInvocationID.y + {y}][gl_LocalInvocationID.x + {x}];\\n\"\n",
        "\n",
        "            shader_code += f\"    ivec2 store_pos{pass_idx} = ivec2(gl_GlobalInvocationID) * ivec2({passes_out}, 1) + ivec2({pass_idx}, 0);\\n\"\n",
        "            if any(layer_name in current_layer.name for layer_name in [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\"]):\n",
        "                shader_code += f\"    imageStore(out_image, store_pos{pass_idx}, max(result{pass_idx}, {storage}(0.0)));\\n\"\n",
        "            else:\n",
        "                shader_code += f\"    imageStore(out_image, store_pos{pass_idx}, result{pass_idx});\\n\"\n",
        "\n",
        "    elif \"depth\" in current_layer.name:\n",
        "        shader_code += \"void hook() {\\n\"\n",
        "        shader_code += f\"    vec4 result = vec4(0.0, 0.0, 0.0, 1.0);\\n\"\n",
        "        shader_code += f\"    vec2 f0 = fract({previous_layer.name}_pos * {previous_layer.name}_size);\\n\"\n",
        "        shader_code += f\"    ivec2 i0 = ivec2(f0 * vec2(2.0));\\n\"\n",
        "        shader_code += f\"    result.x = {previous_layer.name}_tex((vec2(0.5) - f0) * {previous_layer.name}_pt + {previous_layer.name}_pos)[i0.y * 2 + i0.x];\\n\"\n",
        "        shader_code += f\"    imageStore(out_image, ivec2(gl_GlobalInvocationID), clamp(result, 0.0, 1.0));\\n\"\n",
        "    shader_code += \"}\\n\\n\"\n",
        "\n",
        "    return shader_code\n",
        "\n",
        "################################################################################\n",
        "filters = model.layers[1].filters\n",
        "shader_code = \"\"\"// MIT License\n",
        "\n",
        "// Copyright (c) 2024 Joao Chrisostomo\n",
        "\n",
        "// Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "// of this software and associated documentation files (the \"Software\"), to deal\n",
        "// in the Software without restriction, including without limitation the rights\n",
        "// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "// copies of the Software, and to permit persons to whom the Software is\n",
        "// furnished to do so, subject to the following conditions:\n",
        "\n",
        "// The above copyright notice and this permission notice shall be included in all\n",
        "// copies or substantial portions of the Software.\n",
        "\n",
        "// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "// SOFTWARE.\n",
        "\n",
        "\"\"\"\n",
        "for i in range(1, len(model.layers)):\n",
        "    if model.layers[i].name == \"conv2d\":\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], 1, filters)\n",
        "    elif model.layers[i].name == \"conv2d_6\":\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], filters, 4)\n",
        "    elif \"conv2d_\" in model.layers[i].name:\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], filters, filters)\n",
        "    elif model.layers[i].name == \"depth_to_space\":\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], 4, 1)\n",
        "\n",
        "print(shader_code)\n",
        "with open(\"meme.glsl\", mode=\"w\") as f:\n",
        "    f.write(shader_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tf2onnx\n",
        "!pip install onnx\n",
        "\n",
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "import onnx\n",
        "\n",
        "input_signature = [tf.TensorSpec([1, None, None, 1], tf.float32, name='input')]\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(model=model, input_signature=input_signature, inputs_as_nchw=['input'], outputs_as_nchw=['depth_to_space'])\n",
        "onnx.save(onnx_model, \"/content/c16f64.onnx\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
