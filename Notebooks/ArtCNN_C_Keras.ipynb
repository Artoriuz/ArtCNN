{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "UpPergUcu9_U",
        "outputId": "0dc8dcc3-0753-4f25-8028-6741598ec952"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade keras\n",
        "#!pip install --upgrade tensorflow\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import keras\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "# For JAX backend\n",
        "# class DepthToSpace(keras.layers.Layer):\n",
        "#     def __init__(self, block_size):\n",
        "#         super().__init__()\n",
        "#         self.block_size = block_size\n",
        "\n",
        "#     def call(self, input):\n",
        "#         batch, height, width, depth = keras.ops.shape(input)\n",
        "#         depth = depth // (self.block_size**2)\n",
        "#         x = keras.ops.reshape(input, [batch, height, width, self.block_size, self.block_size, depth])\n",
        "#         x = keras.ops.transpose(x, [0, 1, 3, 2, 4, 5])\n",
        "#         x = keras.ops.reshape(x, [batch, height * self.block_size, width * self.block_size, depth])\n",
        "#         x = keras.activations.relu(x, max_value=1.0)\n",
        "#         return x\n",
        "\n",
        "class DepthToSpace(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = tf.nn.depth_to_space(x, 2)\n",
        "        x = tf.clip_by_value(x, 0.0, 1.0)\n",
        "        return x\n",
        "\n",
        "# Settings\n",
        "filters = 32\n",
        "\n",
        "# Build the model:\n",
        "inputs = keras.layers.Input(shape=(None,None,1))\n",
        "conv0 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same')(inputs)\n",
        "\n",
        "# Internal convolutions\n",
        "conv1 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv0)\n",
        "conv2 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv1)\n",
        "conv3 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
        "conv4 = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same', activation='relu')(conv3)\n",
        "\n",
        "# Feature Fusion\n",
        "mix_global = keras.layers.Conv2D(filters=filters, kernel_size=3, padding='same')(conv4)\n",
        "add_global = keras.layers.Add()([mix_global, conv0])\n",
        "\n",
        "# Upsampler\n",
        "features = keras.layers.Conv2D(filters=4, kernel_size=3, padding='same')(add_global)\n",
        "outputs = DepthToSpace()(features)\n",
        "\n",
        "# Defining the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "# model.load_weights(\"/content/c4f32.keras\", skip_mismatch=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tzCPOOqY99d",
        "outputId": "f1b794ce-ba19-4320-c7e6-07b295e34d7f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/tmp/c4f32.keras /content/c4f32.keras\n",
        "!cp /content/drive/MyDrive/Datasets/Anime_Train_HR.zip /content/HR1.zip\n",
        "!cp /content/drive/MyDrive/Datasets/Digital_Art_Train_HR.zip /content/HR2.zip\n",
        "!unzip /content/HR1.zip\n",
        "!unzip /content/HR2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HasfENyG8Ix1",
        "outputId": "226f6600-7407-4fa8-8de3-8764a7ef7777"
      },
      "outputs": [],
      "source": [
        "# Single Dataset Gray\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "filelist = sorted(glob.glob('/content/HR/*.png'))\n",
        "train_ref = []\n",
        "train_in = []\n",
        "\n",
        "for myFile in filelist:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    image = np.array(image).astype(np.float32) / 255.0\n",
        "    image = np.clip(image, 0.0, 1.0)\n",
        "    train_ref.append(image.copy())\n",
        "    train_in = cv2.resize(image.copy(), None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT)\n",
        "    train_in = np.clip(train_in, 0.0, 1.0)\n",
        "    train_in.append(image)\n",
        "\n",
        "train_ref = np.array(train_ref)\n",
        "train_ref = np.expand_dims(train_ref, axis=-1)\n",
        "print(train_ref.shape)\n",
        "\n",
        "train_in = np.array(train_in)\n",
        "train_in = np.expand_dims(train_in, axis=-1)\n",
        "print(train_in.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZMKD09lMVpU"
      },
      "outputs": [],
      "source": [
        "# Separate HR and LR\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "filelist1 = sorted(glob.glob('/content/LR/*.png'))\n",
        "train_in = []\n",
        "for myFile in filelist1:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    train_in.append(image)\n",
        "train_in = np.array(train_in).astype(np.float32) / 255.0\n",
        "train_in = np.clip(train_in, 0.0, 1.0)\n",
        "train_in = np.expand_dims(train_in, axis=-1)\n",
        "print(train_in.shape)\n",
        "\n",
        "filelist2 = sorted(glob.glob('/content/HR/*.png'))\n",
        "train_ref = []\n",
        "for myFile in filelist2:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    train_ref.append(image)\n",
        "train_ref = np.array(train_ref).astype(np.float32) / 255.0\n",
        "train_ref = np.clip(train_ref, 0.0, 1.0)\n",
        "train_ref = np.expand_dims(train_ref, axis=-1)\n",
        "print(train_ref.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82joGvWhZRgN",
        "outputId": "7143f6c6-1890-46f5-80b1-c2e6da25e175"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.compile(optimizer=keras.optimizers.AdamW(learning_rate=0.00005), loss=keras.losses.MeanAbsoluteError())\n",
        "history = model.fit(train_in, train_ref, epochs=500, batch_size=8, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMr-4ei_yY27"
      },
      "outputs": [],
      "source": [
        "# Make a single prediction\n",
        "input = cv2.imread('/content/downscaled.png', cv2.IMREAD_COLOR)\n",
        "input = cv2.cvtColor(input, cv2.COLOR_BGR2GRAY, 0)\n",
        "input = np.array(input).astype(np.float32) / 255.0\n",
        "input = np.clip(input, 0.0, 1.0)\n",
        "input = np.expand_dims(input, axis=0)\n",
        "input = np.expand_dims(input, axis=-1)\n",
        "\n",
        "pred = model.predict(input)\n",
        "pred = np.clip(pred, 0.0, 1.0)\n",
        "pred = np.squeeze(pred)\n",
        "pred = pred * 255.0\n",
        "pred = np.squeeze((np.around(pred)).astype(np.uint8))\n",
        "\n",
        "cv2.imwrite('/content/prediction.png', pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r8DoTvebYWf"
      },
      "outputs": [],
      "source": [
        "# Make a single RGB prediction\n",
        "input = cv2.imread('/content/aoko.png', cv2.IMREAD_COLOR)\n",
        "input = np.array(input).astype(np.float32) / 255.0\n",
        "input = np.clip(input, 0.0, 1.0)\n",
        "(input_b, input_g, input_r) = cv2.split(input)\n",
        "input_b = np.expand_dims(input_b, axis=0)\n",
        "input_g = np.expand_dims(input_g, axis=0)\n",
        "input_r = np.expand_dims(input_r, axis=0)\n",
        "input_b = np.expand_dims(input_b, axis=-1)\n",
        "input_g = np.expand_dims(input_g, axis=-1)\n",
        "input_r = np.expand_dims(input_r, axis=-1)\n",
        "\n",
        "pred_b = model.predict(input_b)\n",
        "pred_g = model.predict(input_g)\n",
        "pred_r = model.predict(input_r)\n",
        "pred = np.stack((pred_b, pred_g, pred_r), axis=-1)\n",
        "pred = np.clip(pred, 0.0, 1.0)\n",
        "pred = np.squeeze(pred)\n",
        "pred = pred * 255.0\n",
        "pred = np.squeeze((np.around(pred)).astype(np.uint8))\n",
        "\n",
        "cv2.imwrite('/content/prediction.png', pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF6B5gOVil9K"
      },
      "outputs": [],
      "source": [
        "#Generate fragment shader\n",
        "import numpy as np\n",
        "\n",
        "def generate_shader_code(current_layer, previous_layer, channels_in, channels_out):\n",
        "    passes_in = int(np.ceil(channels_in / 4))\n",
        "    passes_out = int(np.ceil(channels_out / 4))\n",
        "\n",
        "    if previous_layer.name == \"input_layer\":\n",
        "        previous_layer.name = \"LUMA\"\n",
        "\n",
        "    shader_code = \"\"\n",
        "    for pass_idx in range(passes_out):\n",
        "        if any(layer_name in current_layer.name for layer_name in [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\"]):\n",
        "            shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')}-ReLU)\\n\" #-{pass_idx}\n",
        "        elif \"conv2d\" in current_layer.name:\n",
        "            shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')})\\n\"\n",
        "        else:\n",
        "            shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')})\\n\"\n",
        "\n",
        "        shader_code += f\"//!HOOK LUMA\\n\"\n",
        "\n",
        "        if previous_layer.name == \"LUMA\":\n",
        "            shader_code += f\"//!BIND {previous_layer.name}\\n\"\n",
        "        elif \"add\" in previous_layer.name:\n",
        "            for i in range(passes_in):\n",
        "                shader_code += f\"//!BIND conv2d_{i}\\n\"\n",
        "                shader_code += f\"//!BIND conv2d_5_{i}\\n\"\n",
        "        elif \"conv2d\" in current_layer.name:\n",
        "            for i in range(passes_in):\n",
        "                shader_code += f\"//!BIND {previous_layer.name}_{i}\\n\"\n",
        "        elif \"depth\" in current_layer.name:\n",
        "            shader_code += f\"//!BIND {previous_layer.name}_0\\n\"\n",
        "\n",
        "        if \"depth\" in current_layer.name:\n",
        "            shader_code += f\"//!WIDTH LUMA.w 2.0 *\\n\"\n",
        "            shader_code += f\"//!HEIGHT LUMA.h 2.0 *\\n\"\n",
        "        else:\n",
        "            shader_code += f\"//!SAVE {current_layer.name}_{pass_idx}\\n\"\n",
        "            shader_code += f\"//!WIDTH LUMA.w\\n\"\n",
        "            shader_code += f\"//!HEIGHT LUMA.h\\n\"\n",
        "\n",
        "        shader_code += f\"//!COMPONENTS 4\\n\"\n",
        "        shader_code += f\"//!WHEN OUTPUT.w LUMA.w / 1.3 > OUTPUT.h LUMA.h / 1.3 > *\\n\\n\"\n",
        "        shader_code += \"vec4 hook() {\\n\"\n",
        "\n",
        "        if \"conv2d\" in current_layer.name:\n",
        "            biases = current_layer.get_weights()[1][pass_idx*4:(pass_idx+1)*4]\n",
        "            biases_str = \", \".join(str(w) for w in biases.flatten())\n",
        "            shader_code += f\"    vec4 result = vec4({biases_str});\\n\"\n",
        "\n",
        "            for z in range(passes_in):\n",
        "                for y in range(-1, 2):\n",
        "                    for x in range(-1, 2):\n",
        "                        weights = current_layer.get_weights()[0][y+1, x+1, z*4:(z+1)*4, pass_idx*4:(pass_idx+1)*4]\n",
        "                        weights_str = \", \".join(str(w) for w in weights.flatten())\n",
        "\n",
        "                        if weights_str:\n",
        "                            if previous_layer.name == \"LUMA\":\n",
        "                                shader_code += f\"    result += vec4({weights_str}) * {previous_layer.name}_texOff(vec2({x}, {y})).x;\\n\"\n",
        "                            elif \"add\" in previous_layer.name:\n",
        "                                shader_code += f\"    result += mat4({weights_str}) * (conv2d_5_{z}_texOff(vec2({x}, {y})) + conv2d_{z}_texOff(vec2({x}, {y})));\\n\"\n",
        "                            else:\n",
        "                                shader_code += f\"    result += mat4({weights_str}) * {previous_layer.name}_{z}_texOff(vec2({x}, {y}));\\n\"\n",
        "\n",
        "            if any(layer_name in current_layer.name for layer_name in [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\"]):\n",
        "                shader_code += \"    return max(result, vec4(0.0));\\n\"\n",
        "            else:\n",
        "                shader_code += \"    return result;\\n\"\n",
        "\n",
        "        elif \"depth\" in current_layer.name:\n",
        "            shader_code += f\"    vec4 result = vec4(0.0, 0.0, 0.0, 1.0);\\n\"\n",
        "            shader_code += f\"    vec2 f0 = fract({previous_layer.name}_0_pos * {previous_layer.name}_0_size);\\n\"\n",
        "            shader_code += f\"    ivec2 i0 = ivec2(f0 * vec2(2.0));\\n\"\n",
        "            shader_code += f\"    result.x = {previous_layer.name}_0_tex((vec2(0.5) - f0) * {previous_layer.name}_0_pt + {previous_layer.name}_0_pos)[i0.y * 2 + i0.x];\\n\"\n",
        "            shader_code += f\"    return clamp(result, 0.0, 1.0);\\n\"\n",
        "\n",
        "        shader_code += \"}\\n\\n\"\n",
        "    return shader_code\n",
        "\n",
        "################################################################################\n",
        "filters = model.layers[1].filters\n",
        "shader_code = \"\"\"// MIT License\n",
        "\n",
        "// Copyright (c) 2024 Joao Chrisostomo\n",
        "\n",
        "// Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "// of this software and associated documentation files (the \"Software\"), to deal\n",
        "// in the Software without restriction, including without limitation the rights\n",
        "// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "// copies of the Software, and to permit persons to whom the Software is\n",
        "// furnished to do so, subject to the following conditions:\n",
        "\n",
        "// The above copyright notice and this permission notice shall be included in all\n",
        "// copies or substantial portions of the Software.\n",
        "\n",
        "// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "// SOFTWARE.\n",
        "\n",
        "\"\"\"\n",
        "for i in range(1, len(model.layers)):\n",
        "    if model.layers[i].name == \"conv2d\":\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], 1, filters)\n",
        "    elif \"conv2d_6\" in model.layers[i].name:\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], filters, 4)\n",
        "    elif \"conv2d\" in model.layers[i].name:\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], filters, filters)\n",
        "    elif \"depth_to_space\" in model.layers[i].name:\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], 4, 1)\n",
        "\n",
        "print(shader_code)\n",
        "with open(\"fragment.glsl\", mode=\"w\") as f:\n",
        "    f.write(shader_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJlHQDT6Lykx",
        "outputId": "9d30abe8-0e7c-452a-dc08-91a40a50c213"
      },
      "outputs": [],
      "source": [
        "#Generate compute shader\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def find_rect(area):\n",
        "    s = int(math.sqrt(area))\n",
        "    for w in range(s, 0, -1):\n",
        "        if area % w == 0:\n",
        "            h = area // w\n",
        "            return int(max(w, h)), int(min(w, h))\n",
        "\n",
        "def get_tile_off(i, w):\n",
        "    x = i % w\n",
        "    y = i // w\n",
        "    return x, y\n",
        "\n",
        "def generate_shader_code(current_layer, previous_layer, channels_in, channels_out):\n",
        "    if previous_layer.name == \"input_layer\":\n",
        "        previous_layer.name = \"LUMA\"\n",
        "\n",
        "    threads_w, threads_h = 12, 16\n",
        "    tile_w, tile_h = find_rect(np.ceil(channels_out / 4.0))\n",
        "    tile_in_w, tile_in_h = find_rect(np.ceil(channels_in / 4.0))\n",
        "\n",
        "    shader_code = \"\"\n",
        "    if any(layer_name in current_layer.name for layer_name in [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\"]):\n",
        "        shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')}-ReLU)\\n\"\n",
        "    else:\n",
        "        shader_code += f\"//!DESC ArtCNN C4F{filters} ({current_layer.name.title().replace('_', '-')})\\n\"\n",
        "    shader_code += f\"//!COMPUTE {threads_w * tile_w} {threads_h * tile_h} {threads_w} {threads_h}\\n\"\n",
        "    shader_code += f\"//!HOOK LUMA\\n\"\n",
        "\n",
        "    if previous_layer.name == \"LUMA\":\n",
        "        shader_code += f\"//!BIND {previous_layer.name}\\n\"\n",
        "    elif \"add\" in previous_layer.name:\n",
        "        shader_code += f\"//!BIND conv2d\\n\"\n",
        "        shader_code += f\"//!BIND conv2d_5\\n\"\n",
        "    elif \"conv2d\" in current_layer.name:\n",
        "        shader_code += f\"//!BIND {previous_layer.name}\\n\"\n",
        "    elif \"depth\" in current_layer.name:\n",
        "        shader_code += f\"//!BIND {previous_layer.name}\\n\"\n",
        "\n",
        "    if \"depth\" in current_layer.name:\n",
        "        shader_code += f\"//!WIDTH LUMA.w 2.0 *\\n\"\n",
        "        shader_code += f\"//!HEIGHT LUMA.h 2.0 *\\n\"\n",
        "    else:\n",
        "        shader_code += f\"//!SAVE {current_layer.name}\\n\"\n",
        "        shader_code += f\"//!WIDTH LUMA.w {float(tile_w)} *\\n\"\n",
        "        shader_code += f\"//!HEIGHT LUMA.h {float(tile_h)} *\\n\"\n",
        "\n",
        "    shader_code += f\"//!COMPONENTS 4\\n\"\n",
        "    shader_code += f\"//!WHEN OUTPUT.w LUMA.w / 1.3 > OUTPUT.h LUMA.h / 1.3 > *\"\n",
        "    shader_code += \"\"\"\n",
        "#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable\n",
        "#ifdef GL_EXT_shader_explicit_arithmetic_types_float16\n",
        "#\tdefine V4 f16vec4\n",
        "#\tdefine M4 f16mat4\n",
        "#\tdefine F float16_t\n",
        "#else\n",
        "#\tdefine V4 vec4\n",
        "#\tdefine M4 mat4\n",
        "#\tdefine F float\n",
        "#endif\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    if \"conv2d\" in current_layer.name:\n",
        "        storage = \"V4\"\n",
        "        weights_storage = \"M4\"\n",
        "        load_suffix = \"\"\n",
        "        if previous_layer.name == \"LUMA\":\n",
        "            storage = \"F\"\n",
        "            weights_storage = \"V4\"\n",
        "            load_suffix = \".x\"\n",
        "\n",
        "        shader_code += \"const ivec2 ksize = ivec2(3, 3);\\n\"\n",
        "        shader_code += \"const ivec2 offset = ksize / 2;\\n\"\n",
        "        shader_code += \"const ivec2 wg_size = ivec2(gl_WorkGroupSize);\\n\"\n",
        "        shader_code += \"const ivec2 isize = wg_size + ksize - 1;\\n\"\n",
        "        shader_code += f\"shared {storage} inp[{tile_in_w * tile_in_h}][isize.y][isize.x];\\n\"\n",
        "\n",
        "        shader_code += \"void hook() {\\n\"\n",
        "        shader_code += \"    const uvec2 local_xy = gl_LocalInvocationID.xy;\\n\"\n",
        "        shader_code += \"    ivec2 base = ivec2(gl_WorkGroupID) * wg_size;\\n\"\n",
        "        shader_code += \"    for (uint y = local_xy.y; y < isize.y; y += wg_size.y) {\\n\"\n",
        "        shader_code += \"        for (uint x = local_xy.x; x < isize.x; x += wg_size.x) {\\n\"\n",
        "        shader_code += f\"            const ivec2 input_base = (base + ivec2(x,y) - offset) * ivec2({tile_in_w}, {tile_in_h});\\n\"\n",
        "        for z in range(tile_in_w * tile_in_h):\n",
        "            x, y = get_tile_off(z, tile_in_w)\n",
        "            if \"add\" in previous_layer.name:\n",
        "                shader_code += f\"            inp[{z}][y][x] = {storage}(conv2d_5_mul * texelFetch(conv2d_5_raw, input_base + ivec2({x}, {y}), 0) + conv2d_mul * texelFetch(conv2d_raw, input_base + ivec2({x}, {y}), 0){load_suffix});\\n\"\n",
        "            else:\n",
        "                shader_code += f\"            inp[{z}][y][x] = {storage}({previous_layer.name}_mul * texelFetch({previous_layer.name}_raw, input_base + ivec2({x}, {y}), 0){load_suffix});\\n\"\n",
        "\n",
        "        shader_code += \"        }\\n\"\n",
        "        shader_code += \"    }\\n\"\n",
        "        shader_code += \"\\n    barrier();\\n\"\n",
        "\n",
        "        for pass_idx in range(tile_w * tile_h):\n",
        "            biases = current_layer.get_weights()[1][pass_idx*4:(pass_idx+1)*4]\n",
        "            biases_str = \", \".join(str(w) for w in biases.flatten())\n",
        "            shader_code += f\"    V4 result{pass_idx} = V4({biases_str});\\n\"\n",
        "\n",
        "        for z in range(tile_in_w * tile_in_h):\n",
        "            for y in range(0, 3):\n",
        "                for x in range(0, 3):\n",
        "                    shader_code += f\"    const {storage} inp_{z}_{x}_{y} = inp[{z}][local_xy.y + {y}][local_xy.x + {x}];\\n\"\n",
        "            for pass_idx in range(tile_w * tile_h):\n",
        "                for y in range(0, 3):\n",
        "                    for x in range(0, 3):\n",
        "                        weights = current_layer.get_weights()[0][y, x, z*4:(z+1)*4, pass_idx*4:(pass_idx+1)*4]\n",
        "                        weights_str = \", \".join(str(w) for w in weights.flatten())\n",
        "                        if weights_str:\n",
        "                            shader_code += f\"    result{pass_idx} += {weights_storage}({weights_str}) * inp_{z}_{x}_{y};\\n\"\n",
        "\n",
        "        shader_code += f\"    const ivec2 output_base = ivec2(gl_GlobalInvocationID) * ivec2({tile_w}, {tile_h});\\n\"\n",
        "        for pass_idx in range(tile_w * tile_h):\n",
        "            x, y = get_tile_off(pass_idx, tile_w)\n",
        "            if any(layer_name in current_layer.name for layer_name in [\"conv2d_1\", \"conv2d_2\", \"conv2d_3\", \"conv2d_4\"]):\n",
        "                shader_code += f\"    imageStore(out_image, output_base + ivec2({x}, {y}), max(result{pass_idx}, {storage}(0.0)));\\n\"\n",
        "            else:\n",
        "                shader_code += f\"    imageStore(out_image, output_base + ivec2({x}, {y}), result{pass_idx});\\n\"\n",
        "\n",
        "    elif \"depth\" in current_layer.name:\n",
        "        shader_code += \"void hook() {\\n\"\n",
        "        shader_code += f\"    vec4 result = vec4(0.0, 0.0, 0.0, 1.0);\\n\"\n",
        "        shader_code += f\"    vec2 f0 = fract({previous_layer.name}_pos * {previous_layer.name}_size);\\n\"\n",
        "        shader_code += f\"    ivec2 i0 = ivec2(f0 * vec2(2.0));\\n\"\n",
        "        shader_code += f\"    result.x = {previous_layer.name}_tex((vec2(0.5) - f0) * {previous_layer.name}_pt + {previous_layer.name}_pos)[i0.y * 2 + i0.x];\\n\"\n",
        "        shader_code += f\"    imageStore(out_image, ivec2(gl_GlobalInvocationID), clamp(result, 0.0, 1.0));\\n\"\n",
        "    shader_code += \"}\\n\\n\"\n",
        "\n",
        "    return shader_code\n",
        "\n",
        "################################################################################\n",
        "filters = model.layers[1].filters\n",
        "shader_code = \"\"\"// MIT License\n",
        "\n",
        "// Copyright (c) 2024 Joao Chrisostomo, Kacper MichajÅ‚ow\n",
        "\n",
        "// Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "// of this software and associated documentation files (the \"Software\"), to deal\n",
        "// in the Software without restriction, including without limitation the rights\n",
        "// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "// copies of the Software, and to permit persons to whom the Software is\n",
        "// furnished to do so, subject to the following conditions:\n",
        "\n",
        "// The above copyright notice and this permission notice shall be included in all\n",
        "// copies or substantial portions of the Software.\n",
        "\n",
        "// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "// SOFTWARE.\n",
        "\n",
        "\"\"\"\n",
        "for i in range(1, len(model.layers)):\n",
        "    if model.layers[i].name == \"conv2d\":\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], 1, filters)\n",
        "    elif model.layers[i].name == \"conv2d_6\":\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], filters, 4)\n",
        "    elif \"conv2d_\" in model.layers[i].name:\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], filters, filters)\n",
        "    elif model.layers[i].name == \"depth_to_space\":\n",
        "        shader_code += generate_shader_code(model.layers[i], model.layers[i - 1], 4, 1)\n",
        "\n",
        "print(shader_code)\n",
        "with open(\"compute.glsl\", mode=\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(shader_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "9F3rnYiMNF4M",
        "outputId": "78fe5890-4d40-4d70-faea-6e0370e5458c"
      },
      "outputs": [],
      "source": [
        "!pip install tf2onnx\n",
        "!pip install onnx\n",
        "\n",
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "import onnx\n",
        "\n",
        "input_signature = [tf.TensorSpec([1, None, None, 1], tf.float32, name='input')]\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(model=model, input_signature=input_signature, inputs_as_nchw=['input'], outputs_as_nchw=['depth_to_space'])\n",
        "onnx.save(onnx_model, \"/content/c4f32_dft.onnx\")\n",
        "\n",
        "model.save('/content/c4f32.keras')\n",
        "!cp /content/c4f32.keras /content/drive/MyDrive/tmp/c4f32.keras\n",
        "!cp /content/c4f32.onnx /content/drive/MyDrive/tmp/c4f32.onnx"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
