{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56VtMIL-GVvi"
      },
      "outputs": [],
      "source": [
        "!pip install flax\n",
        "!pip install dm_pix\n",
        "!pip install treescope\n",
        "\n",
        "import jax\n",
        "import flax\n",
        "import optax\n",
        "import cv2\n",
        "import glob\n",
        "import dm_pix as pix\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from flax import nnx\n",
        "\n",
        "# Settings\n",
        "filters = 64\n",
        "blocks = 8\n",
        "kernel_size = (3, 3)\n",
        "\n",
        "class ResBlock(nnx.Module):\n",
        "    def __init__(self, *, rngs: nnx.Rngs):\n",
        "        self.conv0 = nnx.Conv(filters, filters, kernel_size=kernel_size, rngs=rngs)\n",
        "        self.conv1 = nnx.Conv(filters, filters, kernel_size=kernel_size, rngs=rngs)\n",
        "        self.conv2 = nnx.Conv(filters, filters, kernel_size=kernel_size, rngs=rngs)\n",
        "\n",
        "    def __call__(self, input):\n",
        "        x = nnx.relu(self.conv0(input))\n",
        "        x = nnx.relu(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return x + input\n",
        "\n",
        "class ArtCNN(nnx.Module):\n",
        "    def __init__(self, *, rngs: nnx.Rngs):\n",
        "        self.conv0 = nnx.Conv(1, filters, kernel_size=kernel_size, rngs=rngs)\n",
        "        self.res_blocks = [ResBlock(rngs=rngs) for _ in range(blocks)]\n",
        "        self.conv1 = nnx.Conv(filters, filters, kernel_size=kernel_size, rngs=rngs)\n",
        "        self.feats_conv = nnx.Conv(filters, 4, kernel_size=kernel_size, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        conv0 = self.conv0(x)\n",
        "        x = conv0\n",
        "        for block in self.res_blocks:\n",
        "            x = block(x)\n",
        "        conv1 = self.conv1(x)\n",
        "        features = self.feats_conv(conv1 + conv0)\n",
        "        outputs = jnp.clip(pix.depth_to_space(features, 2), 0.0, 1.0)\n",
        "        return outputs\n",
        "\n",
        "model = ArtCNN(rngs=nnx.Rngs(0))\n",
        "# nnx.display(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtI6a-2lImmV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Datasets/Anime_Train_HR.zip /content/HR1.zip\n",
        "!cp /content/drive/MyDrive/Datasets/Digital_Art_Train_HR.zip /content/HR2.zip\n",
        "!unzip /content/HR1.zip\n",
        "!unzip /content/HR2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8V58APqJw71"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/HR\n",
        "!rm -rf /content/LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9fpBPE1OaxR"
      },
      "outputs": [],
      "source": [
        "filelist = sorted(glob.glob('/content/HR/*.png'))\n",
        "train_ref = []\n",
        "train_in = []\n",
        "\n",
        "for myFile in filelist:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    train_ref.append(image)\n",
        "    image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT)\n",
        "    train_in.append(image)\n",
        "\n",
        "train_ref = np.array(train_ref).astype(np.float32) / 255.0\n",
        "train_ref = np.clip(train_ref, 0.0, 1.0)\n",
        "train_ref = np.expand_dims(train_ref, axis=-1)\n",
        "print(train_ref.shape)\n",
        "train_ref = jnp.array(train_ref)\n",
        "\n",
        "train_in = np.array(train_in).astype(np.float32) / 255.0\n",
        "train_in = np.clip(train_in, 0.0, 1.0)\n",
        "train_in = np.expand_dims(train_in, axis=-1)\n",
        "print(train_in.shape)\n",
        "train_in = jnp.array(train_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAZUjQu4TrIt"
      },
      "outputs": [],
      "source": [
        "optimizer = nnx.Optimizer(model, optax.adamw(0.0001))\n",
        "batch_size = 16\n",
        "num_epochs = 50\n",
        "metrics_history = {'train_loss': []}\n",
        "\n",
        "def create_batches(x, y, batch_size):\n",
        "    num_samples = x.shape[0]\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        x_batch = x[i:i + batch_size]\n",
        "        y_batch = y[i:i + batch_size]\n",
        "        yield x_batch, y_batch\n",
        "\n",
        "@nnx.jit\n",
        "def train_step(model, optimizer, x, y):\n",
        "    def loss_fn(model):\n",
        "        y_pred = model(x)\n",
        "        loss = jnp.mean(jnp.absolute(y - y_pred))\n",
        "        return loss\n",
        "\n",
        "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
        "    optimizer.update(grads)\n",
        "    return loss\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nStarting epoch {epoch + 1} / {num_epochs}\")\n",
        "    epoch_loss = []  # Track loss for this epoch\n",
        "\n",
        "    for step, (x, y) in enumerate(create_batches(train_in, train_ref, batch_size)):\n",
        "        loss = train_step(model, optimizer, x, y)\n",
        "\n",
        "        metrics_history['train_loss'].append(loss)\n",
        "        epoch_loss.append(loss)\n",
        "\n",
        "        if step % 10 == 0:  # Print every 10 steps\n",
        "            print(f\"[train] epoch: {epoch + 1}, step: {step}, batch loss: {loss:.4f}\")\n",
        "\n",
        "    # Print epoch summary\n",
        "    epoch_avg_loss = jnp.mean(jnp.array(epoch_loss))\n",
        "    print(f\"Epoch {epoch + 1} complete. Average loss: {epoch_avg_loss:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
