{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "56VtMIL-GVvi"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import flax\n",
        "import optax\n",
        "import cv2\n",
        "import glob\n",
        "import dm_pix as pix\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from flax import linen as nn\n",
        "from flax import serialization\n",
        "\n",
        "# Settings\n",
        "filters = 64\n",
        "blocks = 8\n",
        "kernel_size = (3, 3)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    @nn.compact\n",
        "    def __call__(self, input):\n",
        "        x = nn.Conv(features=filters, kernel_size=kernel_size)(input)\n",
        "        x = nn.silu(x)\n",
        "        x = nn.Conv(features=filters, kernel_size=kernel_size)(x)\n",
        "        x = nn.silu(x)\n",
        "        x = nn.Conv(features=filters, kernel_size=kernel_size)(x)\n",
        "        x = x + input\n",
        "        return x\n",
        "\n",
        "class ArtCNN(nn.Module):\n",
        "    @nn.compact\n",
        "    def __call__(self, input):\n",
        "        conv0 = nn.Conv(features=filters, kernel_size=kernel_size)(input)\n",
        "        x = conv0\n",
        "        for _ in range(blocks):\n",
        "            x = ResBlock()(x)\n",
        "        conv1 = nn.Conv(features=filters, kernel_size=kernel_size)(x)\n",
        "        x = conv1 + conv0\n",
        "        x = nn.Conv(features=4, kernel_size=kernel_size)(x)\n",
        "        x = pix.depth_to_space(x, 2)\n",
        "        x = jnp.clip(x, 0.0, 1.0)\n",
        "        return x\n",
        "\n",
        "model = ArtCNN()\n",
        "print(model.tabulate(jax.random.key(0), jnp.ones((1, 128, 128, 1)), compute_flops=True, compute_vjp_flops=True))\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "dummy_input = jnp.ones((1, 128, 128, 1))\n",
        "variables = model.init(key, dummy_input)\n",
        "params = variables['params']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zAKxX8GgLhdp"
      },
      "outputs": [],
      "source": [
        "with open(\"artcnn_params.msgpack\", \"rb\") as f:\n",
        "    params = serialization.from_bytes(params, f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtI6a-2lImmV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Datasets/Anime_Train_HR.zip /content/HR1.zip\n",
        "!cp /content/drive/MyDrive/Datasets/Digital_Art_Train_HR.zip /content/HR2.zip\n",
        "!unzip /content/HR1.zip\n",
        "!unzip /content/HR2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8V58APqJw71"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/HR\n",
        "!rm -rf /content/LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biFDMqAYvqyo"
      },
      "outputs": [],
      "source": [
        "def data_generator(filelist, batch_size):\n",
        "    n_samples = len(filelist)\n",
        "\n",
        "    while True:\n",
        "        random.shuffle(filelist)\n",
        "\n",
        "        for i in range(0, n_samples, batch_size):\n",
        "            batch_files = filelist[i:min(i + batch_size, n_samples)]\n",
        "            train_ref_batch = []\n",
        "            train_in_batch = []\n",
        "\n",
        "            for file in batch_files:\n",
        "                image = cv2.imread(file, cv2.IMREAD_COLOR)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Luma\n",
        "                image = image.astype(np.float32) / 255.0\n",
        "                image = np.clip(image, 0.0, 1.0)\n",
        "\n",
        "                ref_image = np.expand_dims(image.copy(), axis=-1) # Luma\n",
        "                train_ref_batch.append(ref_image)\n",
        "\n",
        "                in_image = cv2.resize(image.copy(), None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT) # Box downscale\n",
        "                in_image = np.clip(in_image, 0.0, 1.0)\n",
        "                in_image = np.expand_dims(in_image, axis=-1) # Luma\n",
        "                train_in_batch.append(in_image)\n",
        "\n",
        "            train_ref_batch = np.array(train_ref_batch)\n",
        "            train_in_batch = np.array(train_in_batch)\n",
        "\n",
        "            yield train_in_batch, train_ref_batch\n",
        "\n",
        "def loss_fn(pred, target):\n",
        "    return jnp.mean(jnp.absolute(target - pred))\n",
        "\n",
        "def forward(params, input, target):\n",
        "    pred = model.apply({'params': params}, input)\n",
        "    loss = loss_fn(pred, target)\n",
        "    return loss\n",
        "\n",
        "@jax.jit\n",
        "def train_step(params, opt_state, input, target):\n",
        "    loss, grads = jax.value_and_grad(forward)(params, input, target)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "    return new_params, opt_state, loss\n",
        "\n",
        "learning_rate = 0.000025\n",
        "optimizer = optax.adamw(learning_rate)\n",
        "opt_state = optimizer.init(params)\n",
        "epochs = 5\n",
        "batch_size = 8\n",
        "filelist = sorted(glob.glob('/content/HR/*.png'))\n",
        "steps_per_epoch = len(filelist) // batch_size\n",
        "train_generator = data_generator(filelist, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgqIqBTm1AbI"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    with tqdm(total=steps_per_epoch, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"step\") as pbar:\n",
        "        for step in range(steps_per_epoch):\n",
        "            batch_in, batch_ref = next(train_generator)\n",
        "            params, opt_state, loss = train_step(params, opt_state, batch_in, batch_ref)\n",
        "            epoch_loss += float(loss)\n",
        "\n",
        "            pbar.set_postfix(loss=float(loss))\n",
        "            pbar.update(1)\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / steps_per_epoch\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}: Average Loss = {avg_epoch_loss:.6f}, Time = {elapsed:.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RDBLab5gLrML"
      },
      "outputs": [],
      "source": [
        "with open(\"artcnn_params.msgpack\", \"wb\") as f:\n",
        "    f.write(serialization.to_bytes(params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEgqPJ52MqOF"
      },
      "outputs": [],
      "source": [
        "# Make a single prediction\n",
        "input = cv2.imread('/content/downscaled.png', cv2.IMREAD_COLOR)\n",
        "input = cv2.cvtColor(input, cv2.COLOR_BGR2GRAY, 0)\n",
        "input = np.array(input).astype(np.float32) / 255.0\n",
        "input = np.clip(input, 0.0, 1.0)\n",
        "input = np.expand_dims(input, axis=0)\n",
        "input = np.expand_dims(input, axis=-1)\n",
        "input = jnp.array(input)\n",
        "\n",
        "pred = model.apply({'params': params}, input)\n",
        "pred = np.array(pred)\n",
        "pred = np.clip(pred, 0.0, 1.0)\n",
        "pred = np.squeeze(pred)\n",
        "pred = pred * 255.0\n",
        "pred = np.squeeze((np.around(pred)).astype(np.uint8))\n",
        "\n",
        "cv2.imwrite('/content/prediction.png', pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
