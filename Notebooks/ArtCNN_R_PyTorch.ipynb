{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "56VtMIL-GVvi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torchsummary import summary\n",
        "\n",
        "filters = 96\n",
        "blocks = 16\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, filters=filters, kernel_size=3):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.act = nn.SiLU()\n",
        "        self.conv0 = nn.Conv2d(filters, filters, kernel_size=kernel_size, padding='same')\n",
        "        self.conv1 = nn.Conv2d(filters, filters, kernel_size=kernel_size, padding='same')\n",
        "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=kernel_size, padding='same')\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.act(self.conv0(input))\n",
        "        x = self.act(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return x + input\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, filters=filters, kernel_size=3, upscale_factor=2):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(1, filters, kernel_size=kernel_size, padding='same')\n",
        "        self.res_blocks = nn.ModuleList([ResBlock() for _ in range(blocks)])\n",
        "        self.conv1 = nn.Conv2d(filters, filters, kernel_size=kernel_size, padding='same')\n",
        "        self.feats_conv = nn.Conv2d(filters, 4, kernel_size=kernel_size, padding='same')\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "    def forward(self, input):\n",
        "        conv0 = self.conv0(input)\n",
        "        x = conv0\n",
        "        for block in self.res_blocks:\n",
        "            x = block(x)\n",
        "        conv1 = self.conv1(x)\n",
        "        x = self.feats_conv(conv1 + conv0)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = torch.clip(x, 0.0, 1.0)\n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "summary(model.cuda(), (1, 256, 256))\n",
        "model.load_state_dict(torch.load(\"/content/r16f96_torch.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtI6a-2lImmV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Datasets/Anime_Train_HR.zip /content/HR1.zip\n",
        "!cp /content/drive/MyDrive/Datasets/Digital_Art_Train_HR.zip /content/HR2.zip\n",
        "!unzip /content/HR1.zip\n",
        "!unzip /content/HR2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "rotations = [0, 90, 180, 270]\n",
        "\n",
        "filelist = sorted(glob.glob('/content/HR/*.png'))\n",
        "\n",
        "for myFile in tqdm(filelist):\n",
        "    img = cv2.imread(myFile, cv2.IMREAD_UNCHANGED)  # Preserve grayscale\n",
        "\n",
        "    if img is None:  # Check if image was read correctly\n",
        "        print(f\"Error reading image: {myFile}\")\n",
        "        continue\n",
        "\n",
        "    for rotation in rotations:\n",
        "        rotated_img = np.rot90(img, rotation // 90) # More efficient rotation\n",
        "        cv2.imwrite(\"/content/HR/\" + str(Path(myFile).stem) + str(rotation) + \".png\", rotated_img)\n",
        "\n",
        "    flipped_img = cv2.flip(img, 1)  # Horizontal flip (flop)\n",
        "\n",
        "    for rotation in rotations:\n",
        "        rotated_flipped_img = np.rot90(flipped_img, rotation // 90)\n",
        "        cv2.imwrite(\"/content/HR/\" + str(Path(myFile).stem) + str(rotation) + \"f.png\", rotated_flipped_img)\n",
        "\n",
        "    os.remove(myFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_Y7_EIsQwEV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class ImagePairDataset(Dataset):\n",
        "    def __init__(self, filelist):\n",
        "        self.filelist = filelist\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filelist)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file = self.filelist[idx]\n",
        "        image = cv2.imread(file, cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        ref_image = image.astype(np.float32) / 255.0\n",
        "        ref_image = np.clip(ref_image, 0.0, 1.0)\n",
        "        ref_image = np.expand_dims(ref_image, axis=0)  # shape: (1, H, W)\n",
        "\n",
        "        in_image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT)\n",
        "        in_image = in_image.astype(np.float32) / 255.0\n",
        "        in_image = np.clip(in_image, 0.0, 1.0)\n",
        "        in_image = np.expand_dims(in_image, axis=0)  # shape: (1, H/2, W/2)\n",
        "\n",
        "        return torch.tensor(in_image, dtype=torch.float32), torch.tensor(ref_image, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoader for training data\n",
        "filelist = sorted(glob.glob('/content/HR/*.png'))\n",
        "train_dataset = ImagePairDataset(filelist)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_function = nn.L1Loss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Move model to device if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"[Epoch {epoch + 1}/{num_epochs}]\", unit=\"batch\")\n",
        "\n",
        "    for inputs, targets in progress_bar:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_function(outputs, targets)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Report progress\n",
        "        progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        # Accumulate loss\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Print epoch statistics\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.8f}')\n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(model.state_dict(), \"/content/r16f96_torch.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TJBCRVEUBQZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image = cv2.imread('/content/downscaled.png', cv2.IMREAD_COLOR)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "image = np.array(image).astype(np.float32) / 255.0\n",
        "image = np.expand_dims(image, axis=-1)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = np.transpose(image, (0, 3, 1, 2))\n",
        "image = torch.tensor(image)\n",
        "\n",
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "image = image.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "\n",
        "output = output.cpu().numpy()\n",
        "output = np.squeeze(output)\n",
        "output = np.clip(output, 0.0, 1.0)\n",
        "output = np.around(output * 255.0)\n",
        "output = output.astype(np.uint8)\n",
        "\n",
        "cv2.imwrite('/content/prediction.png', output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfINCDNYZrCZ"
      },
      "outputs": [],
      "source": [
        "!pip install onnx\n",
        "import onnx\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "x = torch.ones((1, 1, 256, 256))  # N x C x W x H\n",
        "x = x.to(device)\n",
        "torch.onnx.export(\n",
        "    model, x, '/content/r16f64_relu_torch.onnx',\n",
        "    opset_version=20,\n",
        "    input_names = ['input'],\n",
        "    output_names = ['output'],\n",
        "    dynamic_axes={\n",
        "        'input' : {0 : 'batch', 2: 'width', 3: 'height'},\n",
        "        'output' : {0 : 'batch', 2: 'width', 3: 'height'},\n",
        "    }\n",
        ")\n",
        "torch.save(model.state_dict(), \"/content/r16f64_relu_torch.pth\")\n",
        "\n",
        "!cp /content/r8f64_relu_torch.pth /content/drive/MyDrive/tmp/r8f64_relu_torch.pth\n",
        "!cp /content/r8f64_relu_torch.onnx /content/drive/MyDrive/tmp/r8f64_relu_torch.onnx"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
