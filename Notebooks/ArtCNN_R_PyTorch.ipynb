{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "56VtMIL-GVvi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torchsummary import summary\n",
        "\n",
        "filters = 96\n",
        "blocks = 16\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, filters=filters, kernel_size=3):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv0 = nn.Conv2d(filters, filters, kernel_size=kernel_size, padding='same')\n",
        "        self.conv1 = nn.Conv2d(filters, filters, kernel_size=kernel_size, padding='same')\n",
        "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=kernel_size, padding='same')\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.relu(self.conv0(input))\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return x + input\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, filters=filters, kernel_size=3, upscale_factor=2):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(1, filters, kernel_size=kernel_size, padding='same')\n",
        "        self.res_blocks = nn.ModuleList([ResBlock() for _ in range(blocks)])\n",
        "        self.conv1 = nn.Conv2d(filters, filters, kernel_size=kernel_size, padding='same')\n",
        "        self.feats_conv = nn.Conv2d(filters, 4, kernel_size=kernel_size, padding='same')\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "    def forward(self, input):\n",
        "        conv0 = self.conv0(input)\n",
        "        x = conv0\n",
        "        for block in self.res_blocks:\n",
        "            x = block(x)\n",
        "        conv1 = self.conv1(x)\n",
        "        features = self.feats_conv(conv1 + conv0)\n",
        "        outputs = torch.clip(self.pixel_shuffle(features), 0.0, 1.0)\n",
        "        return outputs\n",
        "\n",
        "model = Model()\n",
        "model.load_state_dict(torch.load(\"/content/r8f64_torch.pth\"))\n",
        "summary(model.cuda(), (1, 256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtI6a-2lImmV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Datasets/Anime_Train_HR.zip /content/HR1.zip\n",
        "!cp /content/drive/MyDrive/Datasets/Digital_Art_Train_HR.zip /content/HR2.zip\n",
        "!unzip /content/HR1.zip\n",
        "!unzip /content/HR2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dXVkWHw6tix"
      },
      "outputs": [],
      "source": [
        "# Single Dataset Gray\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "filelist = sorted(glob.glob('/content/HR/*.png'))\n",
        "train_ref = []\n",
        "train_in = []\n",
        "\n",
        "for myFile in filelist:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "    train_ref.append(image)\n",
        "    image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT)\n",
        "    train_in.append(image)\n",
        "\n",
        "train_ref = np.array(train_ref).astype(np.float32) / 255.0\n",
        "train_ref = np.clip(train_ref, 0.0, 1.0)\n",
        "train_ref = np.expand_dims(train_ref, axis=-1)\n",
        "train_ref = np.transpose(train_ref, (0, 3, 1, 2))\n",
        "print(train_ref.shape)\n",
        "\n",
        "train_in = np.array(train_in).astype(np.float32) / 255.0\n",
        "train_in = np.clip(train_in, 0.0, 1.0)\n",
        "train_in = np.expand_dims(train_in, axis=-1)\n",
        "train_in = np.transpose(train_in, (0, 3, 1, 2))\n",
        "print(train_in.shape)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "train_in_tensor = torch.tensor(train_in)\n",
        "train_ref_tensor = torch.tensor(train_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_Y7_EIsQwEV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataset = TensorDataset(train_in_tensor, train_ref_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Move model to device if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to train mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Print epoch statistics\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.8f}')\n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(model.state_dict(), \"/content/r8f64_torch.pth\")\n",
        "!mv /content/r8f64_torch.pth /content/drive/MyDrive/tmp/r8f64_torch.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdlCcqbs3gbf"
      },
      "outputs": [],
      "source": [
        "!mv /content/r8f64_torch.pth /content/drive/MyDrive/tmp/r8f64_torch.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TJBCRVEUBQZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image = cv2.imread('/content/downscaled.png', cv2.IMREAD_COLOR)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0)\n",
        "image = np.array(image).astype(np.float32) / 255.0\n",
        "image = np.expand_dims(image, axis=-1)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = np.transpose(image, (0, 3, 1, 2))\n",
        "image = torch.tensor(image)\n",
        "\n",
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "image = image.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "\n",
        "output = output.cpu().numpy()\n",
        "output = np.squeeze(output)\n",
        "output = np.clip(output, 0.0, 1.0)\n",
        "output = np.around(output * 255.0)\n",
        "output = output.astype(np.uint8)\n",
        "\n",
        "cv2.imwrite('/content/prediction.png', output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfINCDNYZrCZ"
      },
      "outputs": [],
      "source": [
        "!pip install onnx\n",
        "import onnx\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "x = torch.ones((1, 1, 1920, 1080))  # N x C x W x H\n",
        "x = x.to(device)\n",
        "torch.onnx.export(\n",
        "    model, x, '/content/r8f64.onnx',\n",
        "    input_names = ['input'],\n",
        "    output_names = ['output'],\n",
        "    dynamic_axes={\n",
        "        'input' : {0 : 'batch', 2: 'width', 3: 'height'},\n",
        "        'output' : {0 : 'batch', 2: 'width', 3: 'height'},\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
