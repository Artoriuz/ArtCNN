{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WK5UGUltjPnz",
        "outputId": "1eb2d67a-15ff-4598-9b48-eabab4cff594"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "def psnr_metric(y_true, y_pred):\n",
        "    y_pred = tf.clip_by_value(y_pred, clip_value_min=0, clip_value_max=1)\n",
        "    psnr_1 = tf.image.psnr(y_true, y_pred, max_val=1)\n",
        "    return tf.reduce_mean(psnr_1)\n",
        "\n",
        "def ssim_metric(y_true, y_pred):\n",
        "    y_pred = tf.clip_by_value(y_pred, clip_value_min=0, clip_value_max=1)\n",
        "    ssim_1 = tf.image.ssim(y_true, y_pred, max_val=1)\n",
        "    return tf.reduce_mean(ssim_1)\n",
        "\n",
        "# Build the model:\n",
        "inputs = tf.keras.Input(shape=(None,None,1))\n",
        "inputs_conv = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same')(inputs)\n",
        "conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same')(inputs_conv)\n",
        "conv1 = tf.keras.layers.ReLU()(conv1)\n",
        "conv2 = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same')(conv1)\n",
        "conv2 = tf.keras.layers.ReLU()(conv2)\n",
        "conv3 = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same')(conv2)\n",
        "conv3 = tf.keras.layers.ReLU()(conv3)\n",
        "conv4 = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same')(conv3)\n",
        "conv4 = tf.keras.layers.ReLU()(conv4)\n",
        "\n",
        "# Feature Fusion\n",
        "mix_global = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same')(conv4)\n",
        "add_global = tf.keras.layers.Add()([mix_global, inputs_conv])\n",
        "features = tf.keras.layers.Conv2D(filters=4, kernel_size=3, padding='same')(add_global)\n",
        "outputs = tf.nn.depth_to_space(features, 2)\n",
        "\n",
        "# Defining the model\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Defining Adam1\n",
        "Adam1 = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Load weights\n",
        "# model.load_weights(\"/content/model.h5\")\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(optimizer=Adam1, loss=tf.keras.losses.MeanAbsoluteError(), metrics=[psnr_metric, ssim_metric])\n",
        "model.summary()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtI6a-2lImmV",
        "outputId": "963f9981-661a-4050-c2af-3b62f58c00ab"
      },
      "outputs": [],
      "source": [
        "# Copy data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Datasets/Manga109_Train_LR.zip /content/LR.zip\n",
        "!cp /content/drive/MyDrive/Datasets/Manga109_Train_HR.zip /content/HR.zip\n",
        "\n",
        "!unzip /content/LR.zip\n",
        "!unzip /content/HR.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dXVkWHw6tix"
      },
      "outputs": [],
      "source": [
        "# Load data into memory\n",
        "import cv2\n",
        "filelist1 = sorted(glob.glob('/content/LR/*.png'))\n",
        "train_in = []\n",
        "for myFile in filelist1:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_GRAYSCALE)\n",
        "    train_in.append(image)\n",
        "train_in = np.array(train_in).astype(np.float32) / 255.0\n",
        "train_in = tf.clip_by_value(train_in, clip_value_min=0, clip_value_max=1)\n",
        "train_in = np.expand_dims(train_in, axis=3) # comment this for RGB\n",
        "\n",
        "filelist2 = sorted(glob.glob('/content/HR/*.png'))\n",
        "train_ref = []\n",
        "for myFile in filelist2:\n",
        "    image = cv2.imread(myFile, cv2.IMREAD_GRAYSCALE)\n",
        "    train_ref.append(image)\n",
        "train_ref = np.array(train_ref).astype(np.float32) / 255.0\n",
        "train_ref = tf.clip_by_value(train_ref, clip_value_min=0, clip_value_max=1)\n",
        "train_ref = np.expand_dims(train_ref, axis=3) # comment this for RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_3V-q8V6SBF",
        "outputId": "429ad3a4-4106-47a8-eb8d-053e78c44a67"
      },
      "outputs": [],
      "source": [
        "# Train the model.\n",
        "history = model.fit(train_in, train_ref, epochs=1000, batch_size=64, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMr-4ei_yY27",
        "outputId": "ef6d38bb-ab05-425c-9236-3f3fe30b65f1"
      },
      "outputs": [],
      "source": [
        "# Make a single prediction\n",
        "input_bgr = cv2.imread('/content/input.png', cv2.IMREAD_COLOR)\n",
        "input_bgr = np.array(input_bgr).astype(np.float32) / 255.0\n",
        "input_bgr = np.clip(input_bgr, 0, 1)\n",
        "\n",
        "height, width, channels = input_bgr.shape\n",
        "\n",
        "input_ycrcb = cv2.cvtColor(input_bgr, cv2.COLOR_BGR2YCrCb, 0)\n",
        "(input_y, input_cr, input_cb) = cv2.split(input_ycrcb)\n",
        "\n",
        "input_y = np.expand_dims(input_y, axis=0)\n",
        "input_y = np.expand_dims(input_y, axis=3)\n",
        "\n",
        "pred_y = model.predict(input_y)\n",
        "pred_y = np.clip(pred_y, 0, 1)\n",
        "\n",
        "pred_y = np.squeeze(pred_y, axis=0)\n",
        "pred_y = np.squeeze(pred_y, axis=2)\n",
        "\n",
        "inter_cr = cv2.resize(input_cr, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
        "inter_cb = cv2.resize(input_cb, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "pred_ycrcb = np.empty([height * 2, width * 2, channels]).astype(np.float32)\n",
        "pred_ycrcb[:,:,0] = pred_y\n",
        "pred_ycrcb[:,:,1] = inter_cr\n",
        "pred_ycrcb[:,:,2] = inter_cb\n",
        "\n",
        "pred_ycrcb = np.clip(pred_ycrcb, 0, 1)\n",
        "\n",
        "pred_bgr = cv2.cvtColor(pred_ycrcb, cv2.COLOR_YCrCb2BGR, 0)\n",
        "\n",
        "pred_bgr = np.clip(pred_bgr, 0, 1)\n",
        "pred_bgr = pred_bgr * 255\n",
        "pred_bgr = np.squeeze((np.around(pred_bgr)).astype(np.uint8))\n",
        "\n",
        "cv2.imwrite('/content/prediction.png', pred_bgr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPdYO6fxSRv_",
        "outputId": "69cb9fce-4219-4b9a-98f5-b60008816039"
      },
      "outputs": [],
      "source": [
        "model.save('/content/model.h5')\n",
        "model.save('/content/model/')\n",
        "!zip -r model.zip '/content/model/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_8A-YCoDaKD"
      },
      "outputs": [],
      "source": [
        "print(history.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrQNqXNMbSlO"
      },
      "outputs": [],
      "source": [
        "print(history.history['psnr_metric'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVkg57EwbmKG"
      },
      "outputs": [],
      "source": [
        "print(history.history['ssim_metric'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrCX4z3wHej5"
      },
      "outputs": [],
      "source": [
        "!rm /content/model.zip\n",
        "!rm -r /content/content/\n",
        "!rm -r /content/model/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
